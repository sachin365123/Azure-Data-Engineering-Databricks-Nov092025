{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c249d7db-d15a-4711-b7a3-474d36301023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## go to Azure AI Foundry -> Management center -> copy API key and Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eea1e76-8591-4a8b-ab42-2ed5bd5619a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " import os\n",
    "\n",
    " os.environ[\"AZURE_OPENAI_API_KEY\"] = \"4aQ5GYmjbe5e6crb1zPrsrRyXH3nlBn2xxGYZkdrvhZJ1YSUrgH9JQQJ99BHACHrzpqXJ3w3AAAAACOG2uwx\"\n",
    " os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://aifoundrysachin.cognitiveservices.azure.com/\"\n",
    " os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-05-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9672e61-19f9-49c6-85f2-c0c408f231a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " import os\n",
    " from openai import AzureOpenAI\n",
    "\n",
    " client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c959c4d-f5ab-4a0a-b2fe-00b0e8a3fbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's one:\n\nWhy don’t elephants use computers?\n\nBecause they’re afraid of the mouse! \uD83D\uDC18\uD83D\uDDB1️\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-ae1cfeffb1974affbabac5cd8e11b029\"",
      "text/plain": [
       "Trace(request_id=tr-ae1cfeffb1974affbabac5cd8e11b029)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " import mlflow\n",
    " from openai import AzureOpenAI\n",
    "\n",
    " system_prompt = \"Assistant is a large language model trained by OpenAI.\"\n",
    "\n",
    " mlflow.openai.autolog()\n",
    "\n",
    " with mlflow.start_run():\n",
    "\n",
    "     response = client.chat.completions.create(\n",
    "         model=\"gpt-4osachin\",\n",
    "         messages=[\n",
    "             {\"role\": \"system\", \"content\": system_prompt},\n",
    "             {\"role\": \"user\", \"content\": \"Tell me a joke about animals.\"},\n",
    "         ],\n",
    "     )\n",
    "\n",
    "     print(response.choices[0].message.content)\n",
    "     mlflow.log_param(\"completion_tokens\", response.usage.completion_tokens)\n",
    " mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Implement LLMOps with Azure Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c249d7db-d15a-4711-b7a3-474d36301023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## go to Azure AI Foundry -> Management center -> copy API key and Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd10e3c3-c17f-4cff-aeac-ad69ce6a52c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Resource: [https://learn.microsoft.com/en-us/training/modules/fine-tune-azure-databricks/1-introduction](url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eea1e76-8591-4a8b-ab42-2ed5bd5619a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " import os\n",
    "\n",
    " os.environ[\"AZURE_OPENAI_API_KEY\"] = \"4aQ5GYmjbe5e6crb1zPrsrRyXH3nlBn2xxGYZkdrvhZJ1YSUrgH9JQQJ99BHACHrzpqXJ3w3AAAAACOG2uwx\"\n",
    " os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://aifoundrysachin.cognitiveservices.azure.com/\"\n",
    " os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-05-01-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ce3ad61-fdd7-466e-a381-4c40ee805842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Both training_set.jsonl and validation_set.jsonl are made of different conversation examples between user and assistant that will serve as data points for training and validating the fine-tuned model. While the datasets for this exercise are considered small, it is important to keep in mind when working with bigger datasets that the LLMs have a maximum context length in terms of tokens. Therefore, you can verify the token count of your datasets before training your model and revise them if necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9672e61-19f9-49c6-85f2-c0c408f231a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /dbfs/FileStore/fine_tuning/training_set.jsonl\n\n##### Distribution of total tokens:\nmin / max: 47, 62\nmean / median: 52.1, 50.5\n\n##### Distribution of assistant tokens:\nmin / max: 13, 30\nmean / median: 17.6, 15.5\n***************************************************************************\nFile: /dbfs/FileStore/fine_tuning/training_set.jsonl\n\n##### Distribution of total tokens:\nmin / max: 47, 62\nmean / median: 52.1, 50.5\n\n##### Distribution of assistant tokens:\nmin / max: 13, 30\nmean / median: 17.6, 15.5\n***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n##### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "\n",
    "files = ['/dbfs/FileStore/fine_tuning/training_set.jsonl', '/dbfs/FileStore/fine_tuning/training_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"File: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23aebe71-62c4-44ec-988c-621a585c64d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### As a reference, the model used in this exercise, GPT-4o, has the context limit (total number of tokens in the input prompt and the generated response combined) of 128K tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92220b81-dfac-4517-898f-f4c50912c8a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Upload fine-tuning files to Azure OpenAI: Before you start to fine-tune the model, you need to initialize an OpenAI client and add the fine-tuning files to its environment, generating file IDs that will be used to initialize the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c959c4d-f5ab-4a0a-b2fe-00b0e8a3fbd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-7357a0e2c2c845e6baa7aa84811b4bd8\nValidation file ID: file-c4c6a607668c41e1ab704b734066b708\n"
     ]
    }
   ],
   "source": [
    " import os\n",
    " from openai import AzureOpenAI\n",
    "\n",
    " client = AzureOpenAI(\n",
    "   azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "   api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "   api_version = \"2024-05-01-preview\"  # This API version or later is required to access seed/events/checkpoint features\n",
    " )\n",
    "\n",
    " training_file_name = '/dbfs/FileStore/fine_tuning/training_set.jsonl'\n",
    " validation_file_name = '/dbfs/FileStore/fine_tuning/training_set.jsonl'\n",
    "\n",
    " training_response = client.files.create(\n",
    "     file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    " )\n",
    " training_file_id = training_response.id\n",
    "\n",
    " validation_response = client.files.create(\n",
    "     file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    " )\n",
    " validation_file_id = validation_response.id\n",
    "\n",
    " print(\"Training file ID:\", training_file_id)\n",
    " print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e125ad8-e7ff-4544-95e1-18fc9eb2abcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-4o\",\n",
    "    seed = 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3235cb4-9855-4c62-9a0e-5103c45e29a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fine-tuning a model can take over 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a10c1f09-6017-4995-b395-c1a14de8ae34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Submit fine-tuning job: Now that the fine-tuning files have been successfully uploaded you can submit your fine-tuning training job. It isnâ€™t unusual for training to take more than an hour to complete. Once training is completed, you can see the results in Azure AI Foundry by selecting the Fine-tuning option in the left pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5f03591-0a0f-4646-a158-53d48281bf16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### NOTE: You can also monitor the job status in AI Foundry by selecting Fine-tuning in the left sidebar\n",
    "##### jump to Azure AI Foundry -> Fine Tuniing -> Check your model in Queue \"Fine-tune with your own data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3e2c5cb-b0f3-4fbd-aa14-389061bf7be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Wait for the job status changes to **succeeded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e40b88-c9d2-458d-92bd-276ee485d03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-4ab71dc2365443ea8b012b1d1db8e8d3\nStatus: running\n"
     ]
    }
   ],
   "source": [
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7eecc7a8-50ca-4664-8231-6dde92f28e43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Once the job status changes to succeeded, run the following code to get the final results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75f001d-92ad-473d-929d-f11dc496afc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n  \"id\": \"ftjob-4ab71dc2365443ea8b012b1d1db8e8d3\",\n  \"created_at\": 1755584359,\n  \"error\": null,\n  \"fine_tuned_model\": null,\n  \"finished_at\": null,\n  \"hyperparameters\": {\n    \"batch_size\": 1,\n    \"learning_rate_multiplier\": 1.0,\n    \"n_epochs\": 10\n  },\n  \"model\": \"gpt-4o-2024-08-06\",\n  \"object\": \"fine_tuning.job\",\n  \"organization_id\": null,\n  \"result_files\": [\n    \"file-d51fecbeff754eb09e2a127ed6923e74\"\n  ],\n  \"seed\": 105,\n  \"status\": \"running\",\n  \"trained_tokens\": null,\n  \"training_file\": \"file-7357a0e2c2c845e6baa7aa84811b4bd8\",\n  \"validation_file\": \"file-c4c6a607668c41e1ab704b734066b708\",\n  \"estimated_finish\": null,\n  \"integrations\": null,\n  \"metadata\": null,\n  \"method\": null\n}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace4ec6e-e435-4e92-9856-2e7aa56965e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Review the json response and note the unique name generated in the \"fine_tuned_model\" field. It will be used in the following optional task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf82bb72-4ab6-44e3-8384-5c551f5e16e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Deploy fine-tuned model: Now that you have a fine-tuned model, you can deploy it as a customized model and use it like any other deployed model in either the Chat Playground of Azure AI Foundry, or via the chat completion API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a980f6d7-1e3d-44c6-8994-2177894b91f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### replacing the placeholders <YOUR_SUBSCRIPTION_ID>, <YOUR_RESOURCE_GROUP_NAME>, <YOUR_AZURE_OPENAI_RESOURCE_NAME>, and <FINE_TUNED_MODEL>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1fc31c4-1f6d-4401-9abb-18bf55995a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# token = os.getenv(\"TEMP_AUTH_TOKEN\")\n",
    "# subscription = \"<YOUR_SUBSCRIPTION_ID>\"\n",
    "# resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "# resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "# model_deployment_name = \"gpt-4o-ft\"\n",
    "\n",
    "token = os.getenv(\"TEMP_AUTH_TOKEN\")\n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name = \"gpt-4o-ft\"\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"<FINE_TUNED_MODEL>\",\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7551331a-5988-4b00-9f24-2ec9c53cb707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### run the following code to use your customized model in a chat completion call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f43012b-dc08-4323-97ba-fe606b763786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-02-01\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-ft\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Part 6 Fine-Tuning Large Language Models using Azure Databricks and Azure OpenAI",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}